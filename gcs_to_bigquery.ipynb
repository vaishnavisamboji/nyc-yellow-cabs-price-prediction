{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e35d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset boreal-fort-437820-k4.yellow_cab_data created or already exists.\n",
      "Loading avg_fare_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_day...\n",
      "Loaded avg_fare_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_day.\n",
      "Loading avg_fare_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_hour...\n",
      "Loaded avg_fare_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_hour.\n",
      "Loading avg_fare_by_passenger.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_passenger...\n",
      "Loaded avg_fare_by_passenger.csv into table boreal-fort-437820-k4.yellow_cab_data.avg_fare_by_passenger.\n",
      "Loading fare_amount_by_distance.csv into table boreal-fort-437820-k4.yellow_cab_data.fare_amount_by_distance...\n",
      "Loaded fare_amount_by_distance.csv into table boreal-fort-437820-k4.yellow_cab_data.fare_amount_by_distance.\n",
      "Loading final-nyc.csv into table boreal-fort-437820-k4.yellow_cab_data.final_nyc...\n",
      "Loaded final-nyc.csv into table boreal-fort-437820-k4.yellow_cab_data.final_nyc.\n",
      "Loading nyc_yellow_cabs.csv into table boreal-fort-437820-k4.yellow_cab_data.nyc_yellow_cabs...\n",
      "Loaded nyc_yellow_cabs.csv into table boreal-fort-437820-k4.yellow_cab_data.nyc_yellow_cabs.\n",
      "Loading payment_method_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.payment_method_by_hour...\n",
      "Loaded payment_method_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.payment_method_by_hour.\n",
      "Loading payment_method_frequency_ordered.csv into table boreal-fort-437820-k4.yellow_cab_data.payment_method_frequency_ordered...\n",
      "Loaded payment_method_frequency_ordered.csv into table boreal-fort-437820-k4.yellow_cab_data.payment_method_frequency_ordered.\n",
      "Loading peak_pickup_hours.csv into table boreal-fort-437820-k4.yellow_cab_data.peak_pickup_hours...\n",
      "Loaded peak_pickup_hours.csv into table boreal-fort-437820-k4.yellow_cab_data.peak_pickup_hours.\n",
      "Loading revenue_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.revenue_by_day...\n",
      "Loaded revenue_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.revenue_by_day.\n",
      "Loading revenue_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.revenue_by_hour...\n",
      "Loaded revenue_by_hour.csv into table boreal-fort-437820-k4.yellow_cab_data.revenue_by_hour.\n",
      "Loading tips_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.tips_by_day...\n",
      "Loaded tips_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.tips_by_day.\n",
      "Loading trips_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.trips_by_day...\n",
      "Loaded trips_by_day.csv into table boreal-fort-437820-k4.yellow_cab_data.trips_by_day.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import service_account\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Update the path to your service account key file\n",
    "KEY_PATH = \"C:/Users/sambo/Downloads/boreal-fort-437820-k4-0b11a4b50131.json\"\n",
    "\n",
    "# Initialize credentials and clients\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        KEY_PATH,\n",
    "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "    )\n",
    "    project_id = \"boreal-fort-437820-k4\"\n",
    "    bucket_name = \"nyc-yellow-cabs\"\n",
    "    dataset_name = \"yellow_cab_data\"\n",
    "\n",
    "    storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "    bigquery_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing clients: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def create_dataset(dataset_name):\n",
    "    dataset_id = f\"{project_id}.{dataset_name}\"\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"US\"\n",
    "    try:\n",
    "        dataset = bigquery_client.create_dataset(dataset, exists_ok=True)\n",
    "        print(f\"Dataset {dataset_id} created or already exists.\")\n",
    "        return dataset_id\n",
    "    except exceptions.GoogleAPIError as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_csv_to_bigquery(dataset_id, gcs_bucket_name, file_name):\n",
    "    uri = f\"gs://{gcs_bucket_name}/{file_name}\"\n",
    "    table_name = file_name.split(\".\")[0].replace(\"-\", \"_\")\n",
    "    table_id = f\"{dataset_id}.{table_name}\"\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading {file_name} into table {table_id}...\")\n",
    "        load_job = bigquery_client.load_table_from_uri(uri, table_id, job_config=job_config)\n",
    "        load_job.result()  # Waits for the job to complete\n",
    "        print(f\"Loaded {file_name} into table {table_id}.\")\n",
    "    except exceptions.BadRequest as e:\n",
    "        print(f\"Error loading {file_name}: {e}\")\n",
    "    except exceptions.Forbidden as e:\n",
    "        print(f\"Permission denied when loading {file_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error when loading {file_name}: {e}\")\n",
    "\n",
    "def main():\n",
    "    dataset_id = create_dataset(dataset_name)\n",
    "    if not dataset_id:\n",
    "        print(\"Failed to create or access dataset. Exiting.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blobs = bucket.list_blobs()\n",
    "        \n",
    "        for blob in blobs:\n",
    "            if blob.name.lower().endswith('.csv'):\n",
    "                load_csv_to_bigquery(dataset_id, bucket_name, blob.name)\n",
    "    except exceptions.NotFound:\n",
    "        print(f\"Bucket {bucket_name} not found.\")\n",
    "    except exceptions.Forbidden:\n",
    "        print(f\"Permission denied to access bucket {bucket_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50a278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
